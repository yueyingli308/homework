{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "607d387c",
   "metadata": {},
   "source": [
    "## Factor-based stress testing model applied to a Credit Portfolio in a professional financial context. \n",
    "\n",
    "This will involve identifying key factors that influence credit risk, defining stress scenarios, and applying these scenarios to assess the potential impact on the portfolio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685937fd",
   "metadata": {},
   "source": [
    "\n",
    "### Scenario: Stress Testing a Credit Portfolio\n",
    "\n",
    "**Objective**: To evaluate the impact of adverse economic conditions on a credit portfolio using a factor-based model.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Identify Key Factors**: Common risk factors for a credit portfolio include:\n",
    "   - **Interest Rates**: Changes in benchmark interest rates.\n",
    "   - **Credit Spreads**: Widening or narrowing of credit spreads.\n",
    "   - **Economic Growth**: Changes in GDP growth rates.\n",
    "   - **Unemployment Rates**: Changes in the unemployment rate.\n",
    "   - **Inflation Rates**: Changes in inflation.\n",
    "\n",
    "2. **Determine Portfolio Sensitivities**: Estimate how sensitive the portfolio is to changes in these factors. This can be done using historical data and regression analysis.\n",
    "\n",
    "3. **Define Stress Scenarios**: Develop plausible adverse scenarios for these risk factors. For example:\n",
    "   - Severe recession: GDP declines by 5%, unemployment rises by 3%.\n",
    "   - Interest rate spike: Benchmark interest rates increase by 2%.\n",
    "   - Credit spread widening: Credit spreads increase by 200 basis points.\n",
    "\n",
    "4. **Apply the Stress Test**: Use the factor-based model to simulate the impact of these scenarios on the portfolio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a085ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f627941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define historical data for factors and synthetic portfolio returns\n",
    "data = {\n",
    "    'Interest Rate': [0.01, 0.015, 0.02, 0.025, 0.03, 0.035],\n",
    "    'Credit Spread': [0.005, 0.006, 0.007, 0.008, 0.009, 0.01],\n",
    "    'GDP Growth': [0.02, 0.015, 0.01, 0.005, 0.0, -0.005],\n",
    "    'Unemployment Rate': [0.05, 0.055, 0.06, 0.065, 0.07, 0.075],\n",
    "    'Inflation Rate': [0.02, 0.022, 0.024, 0.026, 0.028, 0.03],\n",
    "    'Portfolio Return': [0.04, 0.035, 0.03, 0.025, 0.02, 0.015]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Define factors and portfolio returns\n",
    "factors = df[['Interest Rate', 'Credit Spread', 'GDP Growth', 'Unemployment Rate', 'Inflation Rate']]\n",
    "portfolio_returns = df['Portfolio Return']\n",
    "\n",
    "# Step 3: Calculate sensitivities using linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(factors, portfolio_returns)\n",
    "sensitivities = model.coef_\n",
    "\n",
    "# Create a DataFrame for sensitivities\n",
    "sensitivities_df = pd.DataFrame(sensitivities, index=factors.columns, columns=['Sensitivity'])\n",
    "print(\"Sensitivities:\\n\", sensitivities_df)\n",
    "\n",
    "# Step 4: Define stress scenarios\n",
    "stress_scenarios = {\n",
    "    'Severe Recession': pd.Series({'Interest Rate': -0.01, 'Credit Spread': 0.02, 'GDP Growth': -0.05, 'Unemployment Rate': 0.03, 'Inflation Rate': 0.01}),\n",
    "    'Interest Rate Spike': pd.Series({'Interest Rate': 0.02, 'Credit Spread': 0.005, 'GDP Growth': -0.01, 'Unemployment Rate': 0.01, 'Inflation Rate': 0.02}),\n",
    "    'Credit Spread Widening': pd.Series({'Interest Rate': 0.005, 'Credit Spread': 0.02, 'GDP Growth': -0.01, 'Unemployment Rate': 0.02, 'Inflation Rate': 0.01})\n",
    "}\n",
    "\n",
    "# Step 5: Apply stress scenarios\n",
    "def apply_stress_test(sensitivities, stress_scenarios):\n",
    "    stress_results = {}\n",
    "    for scenario_name, changes in stress_scenarios.items():\n",
    "        stressed_return = sensitivities.dot(changes)\n",
    "        stress_results[scenario_name] = stressed_return\n",
    "    return pd.DataFrame(stress_results, index=['Stressed Return'])\n",
    "\n",
    "# Calculate stressed portfolio returns\n",
    "stressed_portfolio_returns = apply_stress_test(sensitivities, stress_scenarios)\n",
    "print(\"Stressed Portfolio Returns:\\n\", stressed_portfolio_returns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528d90cd",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "1. **Define Historical Data**: We create synthetic historical data for factors and portfolio returns. This includes interest rates, credit spreads, GDP growth, unemployment rate, and inflation rate.\n",
    "\n",
    "2. **Define Factors and Portfolio Returns**: Factors and portfolio returns are extracted from the historical data.\n",
    "\n",
    "3. **Calculate Sensitivities**: Using linear regression, we calculate the sensitivities of the portfolio returns to each factor.\n",
    "\n",
    "4. **Define Stress Scenarios**: Scenarios are defined with assumed changes in factor values. These include a severe recession, an interest rate spike, and credit spread widening.\n",
    "\n",
    "5. **Apply Stress Scenarios**: The function `apply_stress_test` takes the sensitivities and stress scenarios, and calculates the stressed returns for the portfolio under each scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b0f9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e754b30",
   "metadata": {},
   "source": [
    "确保以上例子中的模型是最佳的，可以通过以下步骤进行模型验证、调整和优化。这些步骤包括数据准备、模型选择、验证和优化、以及结果解释和监控。以下是详细步骤：\n",
    "\n",
    "### 1. 数据准备\n",
    "\n",
    "1. **获取高质量数据**：\n",
    "   - 使用可信的数据源获取历史数据，包括经济因素和信用投资组合的回报率。例如，可以使用Bloomberg、Reuters或其他金融数据提供商。\n",
    "\n",
    "2. **数据清洗和预处理**：\n",
    "   - 处理缺失值、异常值，并确保数据的一致性和准确性。\n",
    "   - 将数据标准化或归一化，以便不同因素之间具有可比性。\n",
    "\n",
    "### 2. 模型选择和建立\n",
    "\n",
    "1. **选择合适的模型**：\n",
    "   - 虽然线性回归是一种常用的模型，但可以考虑其他模型如岭回归、Lasso回归或随机森林等，以提高模型的表现。\n",
    "   \n",
    "2. **建立模型**：\n",
    "   ```python\n",
    "   from sklearn.linear_model import Ridge, Lasso\n",
    "   from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "   # 使用不同模型进行回归\n",
    "   models = {\n",
    "       'Linear Regression': LinearRegression(),\n",
    "       'Ridge Regression': Ridge(alpha=1.0),\n",
    "       'Lasso Regression': Lasso(alpha=0.1),\n",
    "       'Random Forest': RandomForestRegressor(n_estimators=100)\n",
    "   }\n",
    "\n",
    "   sensitivities = {}\n",
    "   for name, model in models.items():\n",
    "       model.fit(factors, portfolio_returns)\n",
    "       sensitivities[name] = model.coef_ if name != 'Random Forest' else model.feature_importances_\n",
    "\n",
    "   sensitivities_df = pd.DataFrame(sensitivities, index=factors.columns)\n",
    "   print(\"Sensitivities:\\n\", sensitivities_df)\n",
    "   ```\n",
    "\n",
    "### 3. 模型验证和评估\n",
    "\n",
    "1. **交叉验证**：\n",
    "   - 使用交叉验证（Cross-Validation）来评估模型的稳定性和泛化能力。\n",
    "   ```python\n",
    "   from sklearn.model_selection import cross_val_score\n",
    "\n",
    "   for name, model in models.items():\n",
    "       scores = cross_val_score(model, factors, portfolio_returns, cv=5)\n",
    "       print(f'{name} Cross-Validation Scores: {scores.mean()}')\n",
    "   ```\n",
    "\n",
    "2. **评估指标**：\n",
    "   - 选择合适的评估指标，如均方误差（MSE）、均方根误差（RMSE）、R²等，以评估模型的表现。\n",
    "   ```python\n",
    "   from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "   for name, model in models.items():\n",
    "       model.fit(factors, portfolio_returns)\n",
    "       predictions = model.predict(factors)\n",
    "       mse = mean_squared_error(portfolio_returns, predictions)\n",
    "       r2 = r2_score(portfolio_returns, predictions)\n",
    "       print(f'{name} MSE: {mse}, R²: {r2}')\n",
    "   ```\n",
    "\n",
    "### 4. 模型优化\n",
    "\n",
    "1. **超参数调优**：\n",
    "   - 使用网格搜索（Grid Search）或随机搜索（Random Search）来调优模型的超参数。\n",
    "   ```python\n",
    "   from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "   # 示例：岭回归的超参数调优\n",
    "   ridge = Ridge()\n",
    "   params = {'alpha': [0.1, 1.0, 10.0, 100.0]}\n",
    "   grid_search = GridSearchCV(ridge, param_grid=params, cv=5)\n",
    "   grid_search.fit(factors, portfolio_returns)\n",
    "   print(f'Best parameters for Ridge: {grid_search.best_params_}')\n",
    "   ```\n",
    "\n",
    "2. **特征选择**：\n",
    "   - 使用特征选择方法（如递归特征消除RFE）来确定最重要的因素，从而简化模型并提高预测精度。\n",
    "   ```python\n",
    "   from sklearn.feature_selection import RFE\n",
    "\n",
    "   # 示例：使用递归特征消除选择特征\n",
    "   rfe = RFE(estimator=LinearRegression(), n_features_to_select=3)\n",
    "   rfe.fit(factors, portfolio_returns)\n",
    "   selected_features = factors.columns[rfe.support_]\n",
    "   print(f'Selected Features: {selected_features}')\n",
    "   ```\n",
    "\n",
    "### 5. 结果解释和监控\n",
    "\n",
    "1. **解释模型结果**：\n",
    "   - 分析和解释模型的敏感度结果，确保其具有现实意义和可解释性。\n",
    "   \n",
    "2. **定期监控和更新模型**：\n",
    "   - 定期更新模型和数据，确保其反映最新的市场情况和风险因素。\n",
    "   - 使用实时数据进行模型验证，并根据需要调整模型。\n",
    "\n",
    "3. **压力测试结果应用**：\n",
    "   - 将压力测试的结果应用于风险管理决策，制定相应的风险缓解措施。\n",
    "\n",
    "### 完整代码示例\n",
    "\n",
    "以下是将上述步骤结合起来的完整代码示例：\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Step 1: Define historical data for factors and synthetic portfolio returns\n",
    "data = {\n",
    "    'Interest Rate': [0.01, 0.015, 0.02, 0.025, 0.03, 0.035],\n",
    "    'Credit Spread': [0.005, 0.006, 0.007, 0.008, 0.009, 0.01],\n",
    "    'GDP Growth': [0.02, 0.015, 0.01, 0.005, 0.0, -0.005],\n",
    "    'Unemployment Rate': [0.05, 0.055, 0.06, 0.065, 0.07, 0.075],\n",
    "    'Inflation Rate': [0.02, 0.022, 0.024, 0.026, 0.028, 0.03],\n",
    "    'Portfolio Return': [0.04, 0.035, 0.03, 0.025, 0.02, 0.015]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Define factors and portfolio returns\n",
    "factors = df[['Interest Rate', 'Credit Spread', 'GDP Growth', 'Unemployment Rate', 'Inflation Rate']]\n",
    "portfolio_returns = df['Portfolio Return']\n",
    "\n",
    "# Step 3: Define and evaluate different models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=0.1),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100)\n",
    "}\n",
    "\n",
    "sensitivities = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(factors, portfolio_returns)\n",
    "    sensitivities[name] = model.coef_ if name != 'Random Forest' else model.feature_importances_\n",
    "\n",
    "sensitivities_df = pd.DataFrame(sensitivities, index=factors.columns)\n",
    "print(\"Sensitivities:\\n\", sensitivities_df)\n",
    "\n",
    "# Step 4: Cross-validation scores\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, factors, portfolio_returns, cv=5)\n",
    "    print(f'{name} Cross-Validation Scores: {scores.mean()}')\n",
    "\n",
    "# Step 5: Evaluate model performance\n",
    "for name, model in models.items():\n",
    "    model.fit(factors, portfolio_returns)\n",
    "    predictions = model.predict(factors)\n",
    "    mse = mean_squared_error(portfolio_returns, predictions)\n",
    "    r2 = r2_score(portfolio_returns, predictions)\n",
    "    print(f'{name} MSE: {mse}, R²: {r2}')\n",
    "\n",
    "# Step 6: Hyperparameter tuning for Ridge Regression\n",
    "ridge = Ridge()\n",
    "params = {'alpha': [0.1, 1.0, 10.0, 100.0]}\n",
    "grid_search = GridSearchCV(ridge, param_grid=params, cv=5)\n",
    "grid_search.fit(factors, portfolio_returns)\n",
    "print(f'Best parameters for Ridge: {grid_search.best_params_}')\n",
    "\n",
    "# Step 7: Feature selection using Recursive Feature Elimination (RFE)\n",
    "rfe = RFE(estimator=LinearRegression(), n_features_to_select=3)\n",
    "rfe.fit(factors, portfolio_returns)\n",
    "selected_features = factors.columns[rfe.support_]\n",
    "print(f'Selected Features: {selected_features}')\n",
    "\n",
    "# Step 8: Define stress scenarios\n",
    "stress_scenarios = {\n",
    "    'Severe Recession': pd.Series({'Interest Rate': -0.01, 'Credit Spread': 0.02, 'GDP Growth': -0.05, 'Unemployment Rate': 0.03, 'Inflation Rate': 0.01}),\n",
    "    'Interest Rate Spike': pd.Series({'Interest Rate': 0.02, 'Credit Spread': 0.005, 'GDP Growth': -0.01, 'Unemployment Rate': 0.01, 'Inflation Rate': 0.02}),\n",
    "    'Credit Spread Widening': pd.Series({'Interest Rate': 0.005, 'Credit Spread': 0.02, 'GDP Growth': -0.01, 'Unemployment Rate': 0.02, 'Inflation Rate': 0.01})\n",
    "}\n",
    "\n",
    "# Step 9: Apply stress scenarios\n",
    "def apply_stress_test(sensitivities, stress_scenarios):\n",
    "    stress_results = {}\n",
    "    for scenario_name, changes in stress_scenarios.items():\n",
    "        stressed_return = sensitivities.dot(changes)\n",
    "        stress_results[scenario_name\n",
    "\n",
    "] = stressed_return\n",
    "    return pd.DataFrame(stress_results, index=['Stressed Return'])\n",
    "\n",
    "# Calculate stressed portfolio returns\n",
    "best_sensitivities = grid_search.best_estimator_.coef_\n",
    "stressed_portfolio_returns = apply_stress_test(best_sensitivities, stress_scenarios)\n",
    "print(\"Stressed Portfolio Returns:\\n\", stressed_portfolio_returns)\n",
    "```\n",
    "\n",
    "### 确保模型的最佳性：\n",
    "\n",
    "1. **数据质量**：使用高质量和最新的数据。\n",
    "2. **模型评估**：使用交叉验证和多种评估指标来评估模型的稳定性和性能。\n",
    "3. **模型优化**：通过超参数调优和特征选择优化模型。\n",
    "4. **结果验证**：与业务专家和历史事件进行对比，验证模型结果的合理性。\n",
    "5. **持续监控**：定期更新模型和数据，确保模型的持续有效性。\n",
    "\n",
    "通过这些步骤，可以确保模型在不同经济场景下的可靠性和准确性，有效评估信用投资组合在压力条件下的风险。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1679a3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "466e10c8",
   "metadata": {},
   "source": [
    "## 将 `Random Forest`、`XGBoost` 和 `Artificial Neural Networks (ANN)` 加入模型选择范围\n",
    "\n",
    "这些模型在处理复杂和非线性关系时可能表现得更好。我们将分别引入 `RandomForestRegressor`、`XGBRegressor` 和 `MLPRegressor` 模型，并对这些模型进行评估和优化。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1659d849",
   "metadata": {},
   "source": [
    "\n",
    "### 完整代码示例\n",
    "\n",
    "以下是包括 `Random Forest`、`XGBoost` 和 `ANN` 的完整代码示例：\n",
    "\n",
    "#### 安装必要的包\n",
    "```bash\n",
    "pip install pandas numpy scikit-learn xgboost\n",
    "```\n",
    "\n",
    "#### 创建 Python 脚本\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Step 1: Define historical data for factors and synthetic portfolio returns\n",
    "data = {\n",
    "    'Interest Rate': [0.01, 0.015, 0.02, 0.025, 0.03, 0.035],\n",
    "    'Credit Spread': [0.005, 0.006, 0.007, 0.008, 0.009, 0.01],\n",
    "    'GDP Growth': [0.02, 0.015, 0.01, 0.005, 0.0, -0.005],\n",
    "    'Unemployment Rate': [0.05, 0.055, 0.06, 0.065, 0.07, 0.075],\n",
    "    'Inflation Rate': [0.02, 0.022, 0.024, 0.026, 0.028, 0.03],\n",
    "    'Portfolio Return': [0.04, 0.035, 0.03, 0.025, 0.02, 0.015]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Define factors and portfolio returns\n",
    "factors = df[['Interest Rate', 'Credit Spread', 'GDP Growth', 'Unemployment Rate', 'Inflation Rate']]\n",
    "portfolio_returns = df['Portfolio Return']\n",
    "\n",
    "# Step 3: Define and evaluate different models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=0.1),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100),\n",
    "    'ANN': MLPRegressor(hidden_layer_sizes=(10, 10), max_iter=1000)\n",
    "}\n",
    "\n",
    "sensitivities = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(factors, portfolio_returns)\n",
    "    if name != 'Random Forest' and name != 'XGBoost' and name != 'ANN':\n",
    "        sensitivities[name] = model.coef_\n",
    "    else:\n",
    "        sensitivities[name] = model.feature_importances_ if name != 'ANN' else model.coefs_[0]\n",
    "\n",
    "sensitivities_df = pd.DataFrame(sensitivities, index=factors.columns)\n",
    "print(\"Sensitivities:\\n\", sensitivities_df)\n",
    "\n",
    "# Step 4: Cross-validation scores\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, factors, portfolio_returns, cv=5)\n",
    "    print(f'{name} Cross-Validation Scores: {scores.mean()}')\n",
    "\n",
    "# Step 5: Evaluate model performance\n",
    "for name, model in models.items():\n",
    "    model.fit(factors, portfolio_returns)\n",
    "    predictions = model.predict(factors)\n",
    "    mse = mean_squared_error(portfolio_returns, predictions)\n",
    "    r2 = r2_score(portfolio_returns, predictions)\n",
    "    print(f'{name} MSE: {mse}, R²: {r2}')\n",
    "\n",
    "# Step 6: Hyperparameter tuning for XGBoost and ANN\n",
    "# XGBoost\n",
    "xgb = XGBRegressor()\n",
    "params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "grid_search_xgb = GridSearchCV(xgb, param_grid=params, cv=5)\n",
    "grid_search_xgb.fit(factors, portfolio_returns)\n",
    "print(f'Best parameters for XGBoost: {grid_search_xgb.best_params_}')\n",
    "\n",
    "# ANN\n",
    "ann = MLPRegressor(max_iter=1000)\n",
    "params = {\n",
    "    'hidden_layer_sizes': [(10,), (10, 10), (20, 20)],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1]\n",
    "}\n",
    "grid_search_ann = GridSearchCV(ann, param_grid=params, cv=5)\n",
    "grid_search_ann.fit(factors, portfolio_returns)\n",
    "print(f'Best parameters for ANN: {grid_search_ann.best_params_}')\n",
    "\n",
    "# Step 7: Feature selection using Recursive Feature Elimination (RFE)\n",
    "rfe = RFE(estimator=LinearRegression(), n_features_to_select=3)\n",
    "rfe.fit(factors, portfolio_returns)\n",
    "selected_features = factors.columns[rfe.support_]\n",
    "print(f'Selected Features: {selected_features}')\n",
    "\n",
    "# Step 8: Define stress scenarios\n",
    "stress_scenarios = {\n",
    "    'Severe Recession': pd.Series({'Interest Rate': -0.01, 'Credit Spread': 0.02, 'GDP Growth': -0.05, 'Unemployment Rate': 0.03, 'Inflation Rate': 0.01}),\n",
    "    'Interest Rate Spike': pd.Series({'Interest Rate': 0.02, 'Credit Spread': 0.005, 'GDP Growth': -0.01, 'Unemployment Rate': 0.01, 'Inflation Rate': 0.02}),\n",
    "    'Credit Spread Widening': pd.Series({'Interest Rate': 0.005, 'Credit Spread': 0.02, 'GDP Growth': -0.01, 'Unemployment Rate': 0.02, 'Inflation Rate': 0.01})\n",
    "}\n",
    "\n",
    "# Step 9: Apply stress scenarios\n",
    "def apply_stress_test(sensitivities, stress_scenarios):\n",
    "    stress_results = {}\n",
    "    for scenario_name, changes in stress_scenarios.items():\n",
    "        stressed_return = sensitivities.dot(changes)\n",
    "        stress_results[scenario_name] = stressed_return\n",
    "    return pd.DataFrame(stress_results, index=['Stressed Return'])\n",
    "\n",
    "# Calculate stressed portfolio returns using the best model\n",
    "best_sensitivities = grid_search_xgb.best_estimator_.feature_importances_  # or use grid_search_ann.best_estimator_.coefs_[0] for ANN\n",
    "stressed_portfolio_returns = apply_stress_test(best_sensitivities, stress_scenarios)\n",
    "print(\"Stressed Portfolio Returns:\\n\", stressed_portfolio_returns)\n",
    "```\n",
    "\n",
    "### 说明\n",
    "\n",
    "1. **模型选择**：\n",
    "   - 添加了 `RandomForestRegressor`、`XGBRegressor` 和 `MLPRegressor` 模型。\n",
    "   - 使用这些模型进行训练并计算特征重要性。\n",
    "\n",
    "2. **交叉验证和评估**：\n",
    "   - 使用交叉验证来评估每个模型的稳定性。\n",
    "   - 使用均方误差（MSE）和决定系数（R²）评估模型的表现。\n",
    "\n",
    "3. **超参数调优**：\n",
    "   - 对 `XGBoost` 和 `ANN` 模型进行了超参数调优，以找到最佳参数。\n",
    "\n",
    "4. **特征选择**：\n",
    "   - 使用递归特征消除（RFE）选择最重要的特征。\n",
    "\n",
    "5. **压力测试**：\n",
    "   - 定义不同的压力情景并应用到最佳模型上（例如 `XGBoost` 或 `ANN`），计算在压力条件下的组合回报。\n",
    "\n",
    "通过以上步骤，您可以确保使用最佳的模型来进行压力测试，从而评估信用投资组合在不同经济情景下的风险。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256aff10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73dd0be3",
   "metadata": {},
   "source": [
    "## 在确保上述模型预测的准确性和可靠性方面，除了基本的交叉验证和评估指标，还可以进行以下几种测试和统计检验："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e66788e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 1. 残差分析\n",
    "\n",
    "- **残差图**：绘制预测值与实际值的残差图，检查残差是否呈现随机分布。如果存在系统性模式，可能表明模型存在偏差。\n",
    "- **QQ图**：检查残差是否符合正态分布。\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Residual plot\n",
    "model = LinearRegression()\n",
    "model.fit(factors, portfolio_returns)\n",
    "predictions = model.predict(factors)\n",
    "residuals = portfolio_returns - predictions\n",
    "\n",
    "plt.scatter(predictions, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n",
    "\n",
    "# QQ plot\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('QQ Plot')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 2. 多重共线性检验\n",
    "\n",
    "- **方差膨胀因子（VIF）**：检查特征之间的多重共线性。VIF值较高表示多重共线性问题，需要考虑去除或组合特征。\n",
    "\n",
    "```python\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = factors.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(factors.values, i) for i in range(len(factors.columns))]\n",
    "\n",
    "print(vif_data)\n",
    "```\n",
    "\n",
    "### 3. 模型稳定性检验\n",
    "\n",
    "- **时间序列拆分**：如果数据有时间顺序，可以使用时间序列交叉验证来检验模型在不同时间段的稳定性。\n",
    "- **滚动预测**：使用滚动窗口方法评估模型在随时间变化中的表现。\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_index, test_index in tscv.split(factors):\n",
    "    X_train, X_test = factors.iloc[train_index], factors.iloc[test_index]\n",
    "    y_train, y_test = portfolio_returns.iloc[train_index], portfolio_returns.iloc[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    print(f'Time Series Split MSE: {mse}')\n",
    "```\n",
    "\n",
    "### 4. 偏差-方差分解\n",
    "\n",
    "- **偏差-方差分解**：通过学习曲线分析模型的偏差和方差，判断模型是否存在高偏差或高方差问题。\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(model, factors, portfolio_returns, cv=5, train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training score')\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color='g', label='Cross-validation score')\n",
    "plt.xlabel('Training size')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Learning Curve')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 5. 模型解释性和特征重要性\n",
    "\n",
    "- **特征重要性**：分析模型中各特征的重要性，确保重要特征合理，且符合业务逻辑。\n",
    "- **Shapley值**：使用SHAP (SHapley Additive exPlanations) 分析特征对预测结果的贡献。\n",
    "\n",
    "```python\n",
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(model, factors)\n",
    "shap_values = explainer(factors)\n",
    "\n",
    "shap.summary_plot(shap_values, factors)\n",
    "```\n",
    "\n",
    "### 6. 对比其他模型\n",
    "\n",
    "- **模型对比**：除了目前使用的模型，尝试其他可能的模型，如支持向量机（SVM）、Gradient Boosting等，进行性能对比。\n",
    "- **集成学习**：将多个模型的预测结果进行集成，提高预测的稳健性和准确性。\n",
    "\n",
    "### 7. 数据稳定性检验\n",
    "\n",
    "- **假设检验**：对数据进行各种假设检验，如t检验、卡方检验等，确保数据的统计性质符合模型假设。\n",
    "- **漂移检测**：监测数据分布随时间的变化，检测是否存在数据漂移问题。\n",
    "\n",
    "### 8. 样本外验证\n",
    "\n",
    "- **样本外数据验证**：使用未参与模型训练和验证的数据集（如最近的市场数据或不同的市场区域）进行样本外验证，评估模型在未知数据上的表现。\n",
    "\n",
    "通过上述多种测试和统计检验，可以确保模型预测的可靠性和稳健性，提高在实际应用中的可信度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b026f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d40b995c",
   "metadata": {},
   "source": [
    "在确保模型预测的可靠性和稳健性方面，方差检验、系数检验和残差检验是非常重要的工具。它们各自有不同的目的和作用：\n",
    "\n",
    "### 1. 方差检验 (Variance Tests)\n",
    "\n",
    "#### 方差膨胀因子 (Variance Inflation Factor, VIF)\n",
    "**目的**: 检查多重共线性（即特征之间的高度相关性）。\n",
    "\n",
    "**作用**: VIF 用于评估每个特征对其他特征的线性依赖程度。VIF 值越高，表示该特征与其他特征的相关性越强。\n",
    "\n",
    "```python\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# 计算每个特征的VIF值\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = factors.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(factors.values, i) for i in range(len(factors.columns))]\n",
    "\n",
    "print(vif_data)\n",
    "```\n",
    "\n",
    "**解释**:\n",
    "- VIF = 1: 该特征与其他特征没有多重共线性。\n",
    "- 1 < VIF < 5: 该特征与其他特征有中等程度的多重共线性。\n",
    "- VIF > 5: 该特征与其他特征有严重的多重共线性，可能需要去除或重新组合特征。\n",
    "\n",
    "### 2. 系数检验 (Coefficient Tests)\n",
    "\n",
    "#### t-检验 (t-Test)\n",
    "**目的**: 检查每个回归系数是否显著。\n",
    "\n",
    "**作用**: t-检验用于评估每个回归系数是否显著不同于零，即特征对目标变量的影响是否显著。\n",
    "\n",
    "```python\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 添加常数项（截距）\n",
    "factors_with_const = sm.add_constant(factors)\n",
    "\n",
    "# 使用OLS进行回归\n",
    "model = sm.OLS(portfolio_returns, factors_with_const).fit()\n",
    "\n",
    "# 打印模型摘要\n",
    "print(model.summary())\n",
    "```\n",
    "\n",
    "**解释**:\n",
    "- p-value < 0.05: 回归系数显著不同于零，该特征对目标变量的影响显著。\n",
    "- p-value >= 0.05: 回归系数不显著不同于零，该特征对目标变量的影响可能不显著。\n",
    "\n",
    "### 3. 残差检验 (Residual Tests)\n",
    "\n",
    "#### 残差图 (Residual Plot)\n",
    "**目的**: 检查残差的分布是否随机，是否存在模式。\n",
    "\n",
    "**作用**: 残差图用于发现模型中的系统性误差或非线性关系。\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 绘制残差图\n",
    "predictions = model.predict(factors_with_const)\n",
    "residuals = portfolio_returns - predictions\n",
    "\n",
    "plt.scatter(predictions, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**解释**:\n",
    "- 残差应随机分布，没有明显的模式或趋势。如果残差图中有系统性模式，可能需要重新考虑模型或特征。\n",
    "\n",
    "#### QQ图 (Quantile-Quantile Plot, QQ Plot)\n",
    "**目的**: 检查残差是否符合正态分布。\n",
    "\n",
    "**作用**: QQ图用于判断残差是否服从正态分布，从而验证线性回归模型的正态性假设。\n",
    "\n",
    "```python\n",
    "import scipy.stats as stats\n",
    "\n",
    "# 绘制QQ图\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('QQ Plot')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**解释**:\n",
    "- 残差点应大致落在QQ图上的直线上。如果偏离较大，说明残差不符合正态分布，可能需要转换变量或使用其他模型。\n",
    "\n",
    "#### Durbin-Watson 统计量 (Durbin-Watson Statistic)\n",
    "**目的**: 检查残差是否存在自相关性。\n",
    "\n",
    "**作用**: Durbin-Watson 统计量用于检测残差的自相关性，特别是时间序列数据中的序列相关性。\n",
    "\n",
    "```python\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "# 计算Durbin-Watson统计量\n",
    "dw_stat = durbin_watson(residuals)\n",
    "print('Durbin-Watson statistic:', dw_stat)\n",
    "```\n",
    "\n",
    "**解释**:\n",
    "- Durbin-Watson 值接近2: 残差无自相关性。\n",
    "- Durbin-Watson 值接近0或4: 残差存在正自相关性或负自相关性，可能需要考虑时序模型或加入自相关结构。\n",
    "\n",
    "通过以上这些测试和检验，可以更全面地评估和改进模型的性能，确保模型预测的准确性和可靠性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6e8c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
